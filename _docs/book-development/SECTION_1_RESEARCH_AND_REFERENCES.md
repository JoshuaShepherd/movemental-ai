# Section 1: Research Support & Further Reading

**Purpose:** (1) What 2026 and recent research would support Section 1 if gathered agentically; (2) a footnoted reference list for further reading.  
**Section 1 scope:** Where we are now (re: AI)—kairos, threat landscape, credibility crisis, trust collapse, AI as problem/solution, reframe (anthropological/adaptive), where people are, audience shift, speed of adoption, why movement leaders were right to ignore SEO, new reality (discoverability + network verification).

---

## Part 1: Research That Would Support This Section (Agentic Search Angles)

Use these as search angles for papers, reports, videos, and core work. Each maps to Section 1’s claims or tone.

### Kairos & threat landscape

- **Search:** “AI threats 2023” + “Center for Humane Technology” / “The AI Dilemma” + transcript or slide deck  
- **Why:** The March 2023 “AI Dilemma” talk (Tristan Harris & Aza Raskin) is the reference for the “early-LLM threat list” (racing dynamics, safety gaps, existential risk framing). Good for a footnote and for naming “the list we’re still deciphering.”
- **Also:** “synthetic media threats” + “deepfake” + “AI fraud” 2025–2026; “generative AI enabled fraud” projections ($40B by 2027 type figures).

### Credibility crisis & “what’s real”

- **Search:** “AI credibility crisis” 2025 2026; “trust collapse” + AI; “trust in AI” survey 2025  
- **Key papers/reports:**  
  - “The Collapse of Trust in AI Assistants” (Zenodo 2025)—volatility of model outputs (e.g. 61% materially different answers across runs).  
  - “Technology Trust Crisis 2026” / “$40 Billion Confidence Collapse” style reports—trust metrics and economic impact.  
  - Pew Research and similar: “How Americans View AI” 2025—concern vs excitement (e.g. 50% more concerned than excited).
- **Search:** “percentage of content AI-generated” 2025; “AI-generated articles” share of web  
- **Key stats:** Ahrefs 900k-page study (e.g. 74% of new webpages with AI content, April 2025); Graphite (e.g. >50% of new articles AI-generated); “more articles created by AI than humans” (2024/2025). Update the 40–60% and “can’t tell what’s real” with latest figures.

### Human ability to distinguish human vs AI text

- **Search:** “human detect AI-generated text” 2024 2025; “Turing test” + GPT-4; “AI detection” human accuracy  
- **Key work:**  
  - Study that general participants cannot reliably distinguish GPT-4 from human (e.g. ~54% judged human, near chance).  
  - PMC/NCBI “Ability of AI detection tools and humans to accurately identify…” (2025).  
  - “People who frequently use ChatGPT… accurate and robust detectors” (arxiv 2501.15654)—shows experts vs general population gap.  
- **Use:** Support “most people can’t tell what’s real” and “effective exposure without experience.”

### Volume, polish, presence (signals breakdown)

- **Search:** “credibility signals” + AI; “AI replicate expertise signals”; “volume content” + AI generation rate  
- **Use:** Less a single paper than a synthesis—cite content-prevalence stats (above) plus one or two pieces on “AI can produce in a week what writers produce in a year” or “polish from day one.” Trade/industry reports (e.g. content marketing + AI) are useful.

### Trust collapse & movement leaders

- **Search:** “trust collapse” + “online” or “content”; “skepticism” + “AI content”  
- **Use:** Pew/survey data on concern, desire for control, and “erosion of human abilities” (creative thinking, relationships). Section 1’s “especially movement leaders” is argument, not a study—support with general trust/credibility data plus one sentence on “expertise is hard-won / credibility is relational.”

### AI as both problem and solution

- **Search:** “AI problem and solution” or “dual nature” AI; “using the tool that created the problem”  
- **Use:** Mostly conceptual; optional short footnote to a 2024/2025 think-piece or report that names the same tension. Not essential.

### Anthropological & adaptive leadership reframe

- **Search:** “Heifetz” + “adaptive leadership” + “technical vs adaptive”; “Leadership Without Easy Answers”  
- **Canonical:** Ronald A. Heifetz, *Leadership Without Easy Answers* (Harvard University Press, 1994).  
- **Search:** “AI anthropological” or “AI human flourishing” 2024 2025  
- **Use:** Heifetz for the technical/adaptive distinction; optional one recent paper or report framing AI as “human” or “societal” rather than purely technical.

### Non-technical leaders / interaction via language

- **Search:** “AI interaction” “natural language” “non-experts”; “LLM” “written verbal communication”  
- **Use:** Obvious enough that a single citation (e.g. UX or adoption study showing primary interaction is chat/prompt) suffices, or leave as assertion.

### Where people are (overwhelmed, anxious, overconfident)

- **Search:** “Pew” “AI” “concern” “excited” 2025; “Americans view AI”  
- **Key:** Pew Research Center, “How Americans View AI and Its Impact…” (Sept 2025); “Concern and excitement about AI” (Oct 2025). Gives 50% more concerned than excited, 10% more excited, demographics.  
- **Search:** “AI attitudes” “overwhelmed” “anxious” “by country” or “demographics” 2025  
- **Use:** Tables or one paragraph summarizing “overwhelmed, anxious, disengaged, enthusiastic, overconfident” with percentages.

### Dunning–Kruger & overconfidence with AI

- **Search:** “Dunning-Kruger” “AI” “overconfidence” 2025; “AI use overestimate performance”  
- **Key:**  
  - Aalto University 2025: reversal of Dunning–Kruger with AI—higher AI literacy correlated with *more* overconfidence when using ChatGPT.  
  - arxiv “Confidence is Not Competence” (2510.24772).  
  - “AI use makes us overestimate our cognitive performance” (Tech Xplore summary of 2025 study).  
- **Use:** Footnote for “Dunning–Kruger on steroids” and “effective exposure without wisdom.”

### Audience shift & speed of adoption

- **Search:** “ChatGPT fastest growing” “100 million” “two months”; “fastest adopted technology”  
- **Key:** UBS analyst note (e.g. Reuters, Arstechnica): ChatGPT as fastest-growing consumer app, 100M MAU in two months; comparison to TikTok (9 months), Instagram (2.5 years).  
- **Search:** “ChatGPT users” 2025 2026 (e.g. 900M+ by late 2025).  
- **Use:** “Fastest-adopted” and “speed is an issue”; optional “velocity of language” if you have a specific piece.

### Gatekeepers, SEO, and new credibility (discoverability + network)

- **Search:** “gatekeepers” “credibility” “digital” “publishing”; “network verification” “credibility”  
- **Use:** More conceptual/historical. Optional: media or publishing report on “decline of gatekeepers” or “creator economy” + trust. “Why movement leaders were right to ignore SEO” is argument; “discoverability + network verification” can be supported by one report on trust in networks or recommendations.

### Synthetic media, deepfakes, fraud

- **Search:** “deepfake statistics” 2025; “generative AI fraud” “billion”; “synthetic identity” “fraud” report  
- **Key:**  
  - Entrust 2026 Identity Fraud Report (deepfakes, social engineering, injection attacks).  
  - McAfee “State of the Scamiverse” 2026 (hours spent questioning what’s real, scam volume).  
  - Deepfake growth (e.g. 8M deepfake files 2025 vs 500K 2023), “one in five biometric fraud attempts,” human detection rate for deepfake video (~24.5%).  
- **Use:** Threat list and “we don’t know what’s real” (especially for video/voice).

---

## Part 2: Further Reading — Footnoted Reference List

Curated so Section 1 can be footnoted and readers can go deeper. Ordered by theme to match Section 1’s flow. Format: **Author/Org. Title. Source, date. [1–2 sentence note.]**

---

### A. Kairos, threat landscape, and “the list we’re still deciphering”

1. **Center for Humane Technology.** *The A.I. Dilemma* (presentation). March 9, 2023. San Francisco. Delivered by Tristan Harris and Aza Raskin; transcript and video widely available. [Canonical reference for the early-LLM threat list: racing dynamics, safety gaps, existential risk. Use for “that slide’s list is still the list.”]  
   - Video: *The A.I. Dilemma – Tristan Harris & Aza Raskin*, YouTube (e.g. humanetech.com, March 2023).  
   - Transcript: e.g. ytscribe.com or Center for Humane Technology transcripts.

2. **Entrust.** *2026 Identity Fraud Report*. November 2025 (Business Wire summary). [Deepfakes, social engineering, injection attacks; deepfakes in one in five biometric fraud attempts; voice cloning as top vector.]

3. **McAfee.** *State of the Scamiverse 2026: AI, Deepfakes & Scams – Research Data*. 2026. [Americans spend ~114 hours/year questioning if messages are real; ~14 scam messages/day; 1 in 3 lost money to scams. Supports “can’t tell what’s real” and time cost.]

4. **Deloitte.** *Gen AI Trust, Standards, and Deepfake Disruption*. Technology, Media, and Telecom Predictions 2025. [Deepfake as “cybersecurity-scale challenge”; consequences for trust and institutions.]

---

### B. Credibility crisis, trust collapse, and “what’s real”

5. **Pew Research Center.** *How Americans View AI and Its Impact on Human Abilities, Society*. September 2025. [50% more concerned than excited; 10% more excited; concern about erosion of creative thinking and meaningful relationships.]

6. **Pew Research Center.** *Concern and Excitement About AI*. October 2025. [Demographics and trends; control and oversight attitudes.]

7. **Zenodo / research.** *The Collapse of Trust in AI Assistants: A Practical Examination for Decision Makers*. 2025 (e.g. Zenodo record 17837188). [Volatility of outputs: 61% materially different answers across identical runs; 48% shifted reasoning; 27% contradicted themselves. Supports “trust collapse” and “can’t rely on stability.”]

8. **Axis Intelligence (or equivalent).** *Technology Trust Crisis 2026: The $40 Billion Confidence Collapse*. 2025/2026. [Trust metrics; projected generative AI–enabled fraud losses to $40B by 2027; breach costs.]

9. **ScienceDirect.** *The Impact of Learning About AI Advancements on Trust*. 2025 (e.g. S0160791X25001484). [How information about AI advances affects trust; useful for “trust is fragile.”]

---

### C. How much content is AI, and can people tell?

10. **Ahrefs.** *What Percentage of New Content Is AI-Generated?* Blog/study, April 2025 (900,000 pages). [74.2% of new webpages with AI-generated content; 71.7% mixed human/AI, 25.8% pure human, 2.5% pure AI. Update “40–60%” with this or similar.]

11. **Graphite / coverage.** *More Articles Are Now Created by AI Than Humans*; *AI Content In Search & LLMs*. 2024–2025 (e.g. graphite.io/five-percent). [>50% of new articles AI-generated; AI content share in search and LLM citations. Use for “flood” and “half of what you find.”]

12. **ACM / conference.** *People Cannot Distinguish GPT-4 From a Human in a Turing Test*. 2024/2025 (e.g. ACM DOI 3715275.3732108). [General participants ~54% judge GPT-4 as human; near chance. Supports “most people can’t tell what’s real.”]

13. **PMC / NCBI.** *Ability of AI Detection Tools and Humans to Accurately Identify Different Forms of AI-Generated Written Content*. 2025 (e.g. PMC12752165). [Human and tool accuracy; supports “can’t tell” or “detection is hard.”]

14. **arXiv.** *People Who Frequently Use ChatGPT for Writing Tasks Are Accurate and Robust Detectors of AI-Generated Text*. 2025 (2501.15654). [Frequent users much better than general population; supports “effective exposure without experience” vs “actual use.”]

---

### D. Deepfakes, synthetic media, fraud scale

15. **Deepfake / fraud statistics.** *Deepfake Statistics 2025: AI Fraud Data & Trends* (e.g. deepstrike.io or equivalent). [~8M deepfake files 2025 vs 500K 2023; 3,000% spike in deepfake fraud attempts 2023; human detection rate for high-quality deepfake video ~24.5%.]

16. **Scamwatch HQ / identity fraud.** *Identity Fraud Report 2025–2026: Key Insights and Analysis*. [Synthetic identity, first-party vs third-party fraud; growth in sophisticated fraud.]

---

### E. Dunning–Kruger, overconfidence, and AI

17. **Tech Xplore / Aalto University.** *AI Use Makes Us Overestimate Our Cognitive Performance, Study Reveals*. October 2025. [Summary of reversal of Dunning–Kruger with AI; higher AI literacy → more overconfidence when using ChatGPT.]

18. **arXiv.** *Confidence is Not Competence* (2510.24772). 2025. [Confidence–competence gap with LLMs; mechanistic or empirical. Use for “overconfidence” footnote.]

19. **OpenReview / ICLR 2026.** *LLMs and Overconfidence* (e.g. learning from failure to reduce overconfidence). 2025/2026. [If available: LLM overconfidence and failure feedback. Use for “we haven’t begun to learn.”]

---

### F. Speed of adoption and “fastest technology”

20. **UBS (via Reuters / Arstechnica).** *ChatGPT Sets Record for Fastest-Growing User Base*. February 2023. [100 million MAU in two months; “fastest ramp in a consumer internet app”; TikTok 9 months, Instagram 2.5 years.]

21. **Backlinko / Exploding Topics.** *ChatGPT Statistics 2026: How Many People Use ChatGPT?* 2025/2026. [User counts e.g. 900M+ weekly active; growth timeline. Use for “fastest-adopted” and “speed is an issue.”]

22. **Pew Research Center.** *ChatGPT Usage by Americans* (or similar). 2023–2025. [E.g. 34% of U.S. adults had used ChatGPT by June 2025 vs 18% July 2023; age breakdown. Supports “where people are” and adoption curve.]

---

### G. Adaptive leadership (reframe)

23. **Heifetz, Ronald A.** *Leadership Without Easy Answers*. Cambridge, MA: Belknap Press of Harvard University Press, 1994. ISBN 9780674518582. [Canonical: technical vs adaptive challenges; adaptive work requires learning, loss, and change in people and culture. Essential footnote for “therefore it’s an adaptive leadership task.”]

24. **Harvard / NCS or similar.** *Distinguishing Adaptive From Technical Work* (toolkit or summary). [One-page summary of technical vs adaptive; useful for a short in-text gloss.]

---

### H. Where people are (landscape and attitudes)

25. **Pew Research Center.** *Republicans, Democrats Now Equally Concerned About AI in Daily Life, But Views on Regulation Differ*. November 2025. [Convergence of concern across parties; 50% vs 51% more concerned than excited.]

26. **Pew Research Center.** *How Americans See AI Impacting Human Skills; Its Role in Science, Matchmaking, Religion and More*. September 2025. [Impact on human abilities; creative thinking, relationships; negative vs positive expectations.]

---

### I. Design, citations, and trust in AI systems

27. **arXiv.** *GenAI Search and Trust* (or similar). 2025 (e.g. arxiv 2504.06435). [Reference links/citations increase trust even when hallucinated; highlighting uncertainty can reduce trust. Use if discussing how people evaluate AI output.]

---

## Part 3: Agentic Search Checklist (High Level)

If an agent is doing the gathering:

1. **Update stats:** Replace any “40–60%” or “68%” with latest Ahrefs/Graphite/Pew/ACM-style figures (and note detection limits).
2. **Trust and credibility:** Pull 2025–2026 trust/credibility and “collapse” language from Zenodo, Axis, Pew, and one academic trust paper.
3. **Threat list:** Confirm Center for Humane Technology “AI Dilemma” title, date, and where to link; add one 2025/2026 fraud or deepfake report.
4. **Dunning–Kruger + AI:** Get Aalto 2025 and arxiv 2510.24772 (and Tech Xplore summary) for overconfidence.
5. **Adoption speed:** Get UBS/Reuters and one 2025/2026 user-count source.
6. **Heifetz:** Use *Leadership Without Easy Answers* (1994) as the single adaptive-leadership citation unless you add a second (e.g. Heifetz & Linsky).
7. **Pew:** Use 2–3 Pew titles (Sept/Oct/Nov 2025) for “where people are” and concern/excitement.
8. **Human vs AI detection:** At least one Turing-style study and one “human accuracy” or “detector” paper (ACM, PMC, or arxiv).

---

## Part 4: Suggested Footnote Map to Section 1 Statements

Rough mapping from “Section 1 full chain” to this list (by statement number):

| Statement (short) | Suggested refs from list |
|-------------------|---------------------------|
| 1. Kairos moment | 1 (CHT), 5–6 (Pew), 7 (Zenodo) |
| 2. Core threats still the list | 1, 2, 3, 15, 16 |
| 3. Large share AI, can’t tell | 10, 11, 12, 13 |
| 4. Volume, polish, presence broken | 10, 11 |
| 5. Trust collapse | 5, 6, 7, 8, 9 |
| 6. Movement leaders especially | 5, 6 (Pew concern); rest is argument |
| 7. AI problem and solution | Conceptual; optional 7 or 8 |
| 8. Ignoring not an option, uncritical dangerous | 5, 6, 7 |
| 9. Anthropological, adaptive | 23, 24 |
| 10. Interact via language, non-technical can lead | 23; optional UX study |
| 11. Where people are varied | 5, 6, 22, 25, 26 |
| 12. Dunning–Kruger, overconfidence | 17, 18, 19 |
| 13. Audience shift March → now | 22, 25 (Pew over time) |
| 14. Fastest adopted, speed, VUCA | 20, 21, 22 |
| 15. Right to ignore SEO | Argument; optional gatekeeper/creator economy |
| 16. Gatekeepers losing power, discoverability + network | Optional; 11 (Graphite) for “new content” landscape |
| 17. Adapt not abandon | Conceptual |

---

**End of document.**  
Use Part 1 for agentic search design, Part 2 for footnotes and further reading, Part 3 for an execution checklist, and Part 4 to attach references to specific Section 1 claims.
