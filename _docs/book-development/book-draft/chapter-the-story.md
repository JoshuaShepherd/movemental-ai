# The Story

I want to tell you a story. Not because it's remarkable, but because it's real. Not because I figured it out, but because I didn't stop when I realized I hadn't.

This book is not primarily about AI theory. It's about what happened when I tried to build something real with AI, without knowing how, and refused to stop when it became overwhelming.

The project is called Movemental. It began in early September. And I want to tell you exactly where I was when I started, because I think it matters.

## Where I Started

I did not know anything.

That's not a humble admission—it's a diagnostic reality. This is not a story about a superhuman programmer. In fact, I did not know how to build a database. I did not know backend architecture. 

As a full-stack developer, I had built one or two React apps—maybe three. One of them I launched on the iOS App Store and Android. That process went very quickly. About four weeks. No—actually, a week from start to finish.

That was my experience. And I falsely extrapolated that experience to a vastly more complex system. I thought: if I can build a front-end app in a week, I can build this. I didn't understand the scope of what I was attempting.

So the question is, if you didn't know anything, why did you believe you could do this?

I believed I could do this because I extrapolated from what I was experiencing, what I knew about myself, and my capacity to learn—to know how to solve problems I didn't understand or didn't know how to solve that day. I paired that with what I knew about AI as the technology existed at that moment, and what it could help me figure out.

And then in some way that belief grew during the project because I ended up using a technology I didn't have when I started.

But when I started, what I had was the knowledge that I didn't know how to do this—and that I had never done it before. I was operating with a level of ignorance that I didn't recognize as ignorance.

## What It Became

The scope evolved. I didn't plan this. It just happened.

It started as a tool. Then it became a machine. Then it became a system. Then it became a platform. Then it became a multi-tenant vision connecting real people—Alan Hirsch, Brad Briscoe, and others.

What began as an app to share Alan's work evolved into: an app that showcased AI, then one that demonstrated it, then one that prophetically modeled it. Which evolved into the realization that I already wanted to do this for Brad. Why not connect them? Why not use the same platform in a multi-tenant way?

It was supposed to be for Alan Hirsch. Along the way, we realized we could link Alan Hirsch and Brad Briscoe together.

I was learning daily. Adapting daily. Redesigning the system while building it. Adjusting not only code, but business vision and partnerships in real time. Learning everything I was doing every day—while adapting that learning to an evolving business vision. And doing that while also learning how to work agentically with AI.

There was no stable ground. Every day brought new understanding, new challenges, new decisions. I was building and learning and changing all at once.

If front-end apps take a short amount of time, and the hard work is the system underneath, then building the first app has little to do with the time it takes to build the second. There are complexities there, but the vision was always about multiplication. That vision changed the timeline because it made everything more adaptive.

## The Crisis Point

Around late October, I hit a point of internal crisis.

I had the internal conviction that I might have succumbed to what I understood as AI psychosis—the delusion that I was close to finishing something that would only ever be 80% complete and would fail.

I was afraid the project was an AI-induced delusion. I was afraid I was 80% done forever. I was afraid I had built something unfinishable.

I had been working nights and weekends, alongside a full-time job. I had been building other systems at the same time—six or seven applications, actually. CRM, front ends, moving fast because the front end was so fast. I was stretched thin, and I was starting to wonder if I was building something that couldn't be built.

I didn't know if I could finish. I didn't know if it was worth finishing. I didn't know if I was deluding myself about what was possible.

Essentially, I now know I was operating under a delusion—if the delusion was that I knew how to do this on my current trajectory. There was also a mistake—maybe not a delusion—of not knowing how much time it would take.

## The Friend and the Video

I reached out to the one and only friend I have who is a software developer.

Not to ask for help—but to say, "Look what I'm building."

Probably also to pay lip service to, "It's a little hard," but I don't think I did. I think I just thought, "I'm building this, and I'll get there."

He didn't say much. We talked. He shared a video. It seemed random—just supportive. "Good job." And then, "Here are some cool videos about building with AI."

But I remember watching that video and realizing I was beginning to be concerned that no matter how many times I tried the approach I was taking, it wasn't working.

I was trying that approach across six or seven applications—CRM, front ends—moving fast, because the front end was so fast. And it wasn't working. The approach wasn't working.

## The Turning Point

The turning point didn't come through confidence. It came through rethinking everything.

Over maybe a week—dated around 10/17 or 10/27, about a month and a half into the project—I began working with AI to design a system that would solve the technological problems in a way AI could actually help me.

That led to the creation of what I now call the type-safety chain. I realized I needed to design the system so that AI could actually help. Not just use AI to write code, but design the system in a way that made AI assistance possible, reliable, trustworthy.

I wasn't just building. I was learning how to build in a way that made AI useful, not just present. I was learning how to structure problems so that AI could help solve them.

This wasn't a breakthrough moment. It was a reorientation. A shift in how I was thinking about the problem, not a solution to the problem.

This is important because the project, when conceived not only as a technological project but as a business vision and partnership, has to tell a story of AI's power and potential—for good and bad—alongside a human story. A group of people working it out together.

## The Work

I kept working. Nights and weekends. Alongside a full-time job. Building other systems. Learning daily. Adapting daily. Changing daily.

The work was shared relationally, not privately. With Alan. With Brad. With others. I wasn't doing this alone, and I wasn't doing it in isolation. I shared everything with them during that time, as I had since day one.

I was wrong multiple times. I did not "figure it out." What mattered was refusing to stop grappling, and being willing to change in response to new information, in relationship.

## What I Realize Now

I realize now that I was wrong multiple times. I realize that I did not "figure it out." I realize that what mattered was refusing to stop grappling, and being willing to change in response to new information, in relationship.

I built this thinking I knew something.

I was wrong.

What I did next is changing my life again. I refused to stop experimenting—even when overwhelmed and confused. And I was willing to reconsider everything in light of new information shared in human relationship.

I don't have this figured out. I'm still learning. I'm still wrong about things. I'm still discovering what I don't know.

But I stayed. And I'm still staying. And that's the story I want to tell you.

## Why This Story Matters

If you don't understand the scope of what happened here, you won't understand how AI is changing the world. Any of it.

This isn't a story about someone who knew what they were doing. This is a story about someone who didn't know, and stayed anyway. This is a story about building something real with AI, without knowing how, and refusing to stop when it became overwhelming.

So if we translate the work done into a pre-AI frame and ask, "What happened?"—the truth of what happened is crucial. Because if you don't understand the scope of the work done, then you don't understand how AI is changing the world. Any of it.

If this person didn't know—and stayed—maybe you can stay too.

To alter Robert Frost:

I took the road less traveled.
I did it with friends.
And that has made all the difference.

---

**Document Status**: Final Integrated Version  
**Chapter Function**: Central case study for the book  
**Last Updated**: January 2026  
**Source Material**: Author transcript and narrative retelling  
**Related Documents**:
- `supporting-docs/author-transcripts/transcript-origin-scope-crisis.md` - Source transcript
- `supporting-docs/transcript-analysis.md` - Integration analysis
- `chapter-finding-an-ai-expert.md` - Related chapter on expertise and guidance
- `chapter-aa-where-we-are-processed.md` - Related chapter on audience
