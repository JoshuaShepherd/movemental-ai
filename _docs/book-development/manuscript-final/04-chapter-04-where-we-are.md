# Chapter 4: Where We Are

Where are we? This question matters because where we are determines what we need. And when it comes to AI, where we are is changing rapidly—so rapidly that writing a single book that speaks to everyone's place feels almost impossible.

Let me start with a fundamental reality: AI, as we're experiencing it now, is just over three years old. For everyone except AI scientists and science fiction writers, this is brand new territory. The rest of us never saw this coming. Period.

This matters because it means we're all learning in real time. There's no established playbook. There's no generation of elders who've navigated this before us. We're the first generation to face this particular challenge, and we're doing it while the technology is still evolving at breakneck speed.

I see my role as a guide. In many ways, I've been going down this trail my whole life—thinking about technology, communication, community, and how tools shape us. But in many ways, that trail wasn't possible until three short years ago. I did start on day one. I have not stopped. I have obsessively charted what's possible and terrifying about AI, and I've worked closely with Alan Hirsch and Brad Briscoe to build this.

But where is our audience? This question haunts me because the research reveals something important: we're not all in the same place. Not even close.

According to recent surveys, about 95% of adults have heard at least a little about AI, with 47% saying they've heard a lot—nearly double since 2022. But awareness doesn't mean understanding, and understanding doesn't mean comfort. About 62% of U.S. adults report interacting with AI at least several times a week, but that interaction ranges from casual use to deep integration. Among younger adults under 30, around one-third engage with AI several times a day. But even among regular users, there's significant variation in understanding, comfort, and concern.

The research reveals a landscape of different places:

**The Overwhelmed**: About 50% of U.S. adults say they're more concerned than excited about AI, up from 37% in 2021. Only about 10% say they're more excited than concerned. Roughly 57% rate the risks of AI for society as high or very high, while only 25% say the same about benefits. About 60% want more control over how AI is used in their lives, but only 13% feel they have a lot of control. These are people who feel the technology is moving too fast, who don't understand it, who feel powerless in the face of change.

**The Anxious**: About 49% believe AI will create significant job displacement. About 50% think AI will worsen people's ability to form meaningful relationships. About 53% believe AI will worsen creative thinking. About 67% believe AI will eliminate more jobs than it creates. These are people who see the risks clearly—job loss, erosion of human connection, loss of skills, economic disruption. They're not wrong to be concerned.

**The Disengaged**: While 95% have heard about AI, that still means 5% haven't. And even among those who have heard, many haven't engaged. They're not worried because they're not paying attention. They're not interested because it hasn't touched their lives directly yet. But that's changing rapidly.

**The Enthusiastic Early Adopters**: About one-third of adults under 30 engage with AI several times a day. These are people who've integrated AI into their daily workflows, who see the potential, who are experimenting and learning. But even among this group, there's significant variation in understanding and wisdom about how to use AI well.

**The Overconfident**: Recent research on the Dunning-Kruger effect and AI reveals something troubling: people using AI tend to overestimate their performance and understanding. AI assistance boosts actual performance but inflates self-confidence disproportionately. The classic pattern where low performers overestimate and high performers underestimate is being flattened—now, both groups overestimate when using AI. Counterintuitively, people with higher AI literacy tend to be less accurate about their performance, with more inflated self-assessments. This is the group that thinks they understand AI better than they do.

**The Relationship-Forming**: There's a growing segment of people forming relationships with AI—not just using it as a tool, but engaging with it as a companion, a confidant, even a romantic partner. This raises profound questions about human connection, authenticity, and what it means to relate to non-human entities.

**The Skeptical Experts**: Interestingly, AI researchers and professionals maintain a much more positive outlook than the general public. About 56% of experts believe AI will have a positive impact over the next 20 years, compared to just 17% of the general public. But even experts share concerns about specific risks like bias, misinformation, and misuse of personal data.

Where are we? We're all over the map. And this creates a fundamental challenge: how do we write one book that speaks to people who are overwhelmed, anxious, disengaged, enthusiastic, overconfident, relationship-forming, and skeptical—all at the same time?

But here's the complicating factor: where people are is changing rapidly. Someone who's disengaged today might be overwhelmed tomorrow when AI touches their job. Someone who's enthusiastic today might become anxious tomorrow when they realize the implications. Someone who's overconfident today might become humble tomorrow when they encounter the limits of their understanding.

This rapid change makes me wonder about Dunning-Kruger more than anything. I wonder if we've even begun to learn. The research shows that AI use can lead to "cognitive offloading"—accepting AI's answers without questioning or deeply engaging. This cuts off feedback loops people rely on to calibrate how good they are. So performance might improve, but self-awareness of errors or limitations declines.

Have we even begun to learn? Or are we in the early stages of a massive overconfidence crisis, where we think we understand AI better than we do, where we trust it more than we should, where we've lost the ability to assess our own competence?

I don't know. But I suspect we're still in the early days of learning, and that the real education is just beginning.

This is why I see my role as a guide. Not because I have all the answers—I don't. Not because I've figured it all out—I haven't. But because I've been on this trail from day one, I've been charting what's possible and terrifying, and I've been working to build something that serves movement leaders well.

Where are we? We're in different places, and those places are changing rapidly. But we're all in this together, learning in real time, trying to figure out how to navigate a technology that's reshaping everything—and doing it while the technology itself is still evolving.

The challenge is meeting people where they are while acknowledging that where they are is changing. The opportunity is creating content that can adapt, that can speak to different places, that can serve people whether they're overwhelmed or enthusiastic, anxious or overconfident, disengaged or deeply integrated.

Where are we? We're here, together, learning. And that's where we start.

---

**Reflection Questions:**

1. Where do you find yourself on this landscape? Overwhelmed? Anxious? Enthusiastic? Somewhere else?

2. How has your position changed over the past year? What shifted you?

3. What does the Dunning-Kruger research stir in you? Do you recognize any overconfidence in yourself?
