# Chapter 2: AI Is Not a Technological Challenge

I want to start this chapter with a reframe that might change how you see everything that follows.

AI is not, first and foremost, a technological problem. It's an anthropological one.

This distinction matters because it changes how we understand what we're facing. If AI were primarily a technological problem, we could solve it with better algorithms, more data, faster processors, smarter systems. But AI is fundamentally a human problem—a problem that has to do with questions about human flourishing, relationship, ethics, vocation, change, and what it means to be human in a world where machines can mimic, augment, and potentially replace human capacities.

And here's what I want you to know: the way we actually interact with AI doesn't require technological understanding. We don't "interface" with it in the way we do with code or infrastructure. We talk to it. We write to it. We read what it writes back. It's mostly written or verbal communication. Optimizing and understanding AI does not require you to be technical. Non-technical leaders can lead here. That's good news for movement leaders who create or steward content—you're already experts in communication. The challenge is a people challenge. And therefore it's an adaptive leadership task.

## How We Actually Interact With AI

Let me be clear about what I mean. When I say we interact with AI through written or verbal communication, I mean that's the primary way most of us encounter it. We type a question. We get a response. We refine, we ask again, we iterate. We might speak to it. We might paste in a document and ask for feedback. We're not writing code to "interface" with the system. We're in conversation.

That means the skills that matter are the skills you already have: clarity, specificity, the ability to refine and iterate, the ability to judge whether a response is helpful or off. You don't need to understand how the model works under the hood. You need to understand how to communicate well, how to hold the tension between trust and verification, and how to lead people through change. Those are anthropological skills. Leadership skills. Formation skills.

So when someone tells you that you need to become technical to navigate AI, I want you to push back. You need to become wise about communication, about credibility, about what AI displaces and what it amplifies. You don't need to become an engineer.

## The Anthropological Problem

Why does it help to call this an anthropological problem? Because the research reveals that people aren't worried about the technology itself—they're worried about what it means for human flourishing. About half of people believe AI will worsen their ability to form meaningful relationships. About half believe it will worsen creative thinking. About two-thirds believe it will eliminate more jobs than it creates. These aren't technical concerns. They're anthropological ones. They're questions about what it means to be human, how humans flourish, and how we organize human life in ways that serve human good.

The anthropological problem of AI touches every dimension of human life:

**Human flourishing.** What does it mean to flourish in a world where AI can do many things humans do? If work is essential to human identity and dignity, what happens when AI can do that work? If creativity is central to human expression, what happens when AI can generate creative content? If relationship is fundamental to human flourishing, what happens when people form relationships with AI systems?

**Relationship.** The research shows growing concern about AI's impact on human connection. But it also shows people forming relationships with AI—companions, confidants, even romantic partners. This raises profound questions: What is authentic relationship? Can relationship with AI support or undermine human relationships? How do we navigate the boundary between tool and companion?

**Ethics.** AI forces us to ask fundamental ethical questions: What is the good? Who benefits from AI, and who bears its costs? How do we ensure AI serves human dignity rather than undermining it?

**Vocation.** If work is essential to human identity, what happens when AI can do that work? What is the purpose of human work in an AI age? How do we understand calling and vocation when machines can perform many of the tasks that have defined human work?

**Change.** AI represents change at a scale and speed that's unprecedented. How do humans adapt to such rapid change? What does it mean to lead through change that's happening faster than we can fully understand?

These are not technological questions. They're anthropological ones. And because they're anthropological, they're also adaptive.

## Therefore It's an Adaptive Leadership Task

Adaptive problems are different from technical problems. Technical problems have known solutions that can be applied by experts. Adaptive problems require learning, experimentation, and change—not just in systems, but in people, relationships, and communities.

Ronald Heifetz distinguishes between technical and adaptive challenges. Technical challenges can be solved with existing knowledge and expertise. Adaptive challenges require people to change their values, beliefs, behaviors, and ways of working. AI is fundamentally an adaptive challenge because it requires us to change how we understand ourselves, our work, our relationships, and our communities.

This means that the call to lead with AI is the call to adaptive leadership. Adaptive leadership isn't about having all the answers—it's about creating the conditions for learning, experimentation, and change. It's about helping people navigate uncertainty, ambiguity, and loss. It's about maintaining stability while enabling transformation. It's about holding space for the anxiety, grief, and resistance that come with adaptive change.

Adaptive leadership with AI requires several things:

**Acknowledging loss.** Adaptive change involves loss. When AI changes how we work, relate, and organize, we lose familiar ways of being. Adaptive leaders acknowledge this loss rather than minimizing it. They create space for grief, anxiety, and resistance rather than trying to eliminate it.

**Creating learning environments.** Adaptive challenges require learning, not just training. Adaptive leaders create environments where people can experiment, fail, learn, and adapt. They model learning themselves, showing that they don't have all the answers.

**Holding tension.** Adaptive change involves tension—between old and new, between stability and change, between individual and collective needs. Adaptive leaders hold this tension rather than resolving it prematurely. They help people navigate ambiguity without providing false certainty.

**Protecting voices.** In adaptive change, some voices are marginalized or silenced. Adaptive leaders protect voices that need to be heard, especially voices that challenge the status quo or raise uncomfortable questions.

**Regulating distress.** Adaptive change creates distress. Adaptive leaders help people manage this distress—not by eliminating it, but by keeping it at a productive level where learning can happen.

But here's the crucial point: adaptive leadership cannot be done alone. Adaptive challenges require community. They require people working together, learning together, experimenting together, and supporting each other through change. No leader can navigate adaptive change in isolation.

This is where scenius becomes essential. Scenius—the collaborative genius that emerges from networks of relationships—isn't just a credibility solution. It's a community solution to an adaptive challenge. When movement leaders are connected through scenius, they're not just verifying each other's credibility—they're creating the relationships that enable adaptive learning. The network relationships that form scenius are the same relationships that enable collaborative learning, mutual support, and collective adaptation. We'll get to scenius in more detail later. For now, I want you to hold this: the anthropological problem of AI requires adaptive leadership, which requires community. You don't need to be a technologist. You need to be a leader who can create the conditions for learning and change, in relationship with others.

## What This Means for You

So what does this reframe mean for you, as a movement leader?

First, you're not disqualified because you're not technical. The challenge is a people challenge. You're qualified to lead here precisely because you already lead people—you form them, you communicate with them, you build trust with them.

Second, you're not being asked to have all the answers. You're being asked to create the conditions for learning. To hold tension. To acknowledge loss. To regulate distress. To protect voices. Those are leadership skills you already have or can develop.

Third, you're not alone. Adaptive leadership requires community. The relationships you're building—with other leaders, with your network, with the people who vouch for you and you for them—those aren't optional add-ons. They're the infrastructure that makes adaptive change possible.

AI is not, first and foremost, a technological problem. It's an anthropological one. And that changes everything about how we lead, how we learn, and how we build the communities that will navigate this change together.

---

**Reflection Questions:**

1. Where have you assumed you needed to be "technical" to lead with AI? How does the anthropological reframe change that?

2. What losses have you or your people already experienced as AI has entered your context? How might acknowledging those losses change your leadership?

3. Who is in your community for adaptive learning? Who are you learning with?
