# Chapter 3: Where We Are and Why Now

Where are we? This question matters because where we are determines what we need. And when it comes to AI, where we are is changing rapidly—so rapidly that writing a single book that speaks to everyone's place feels almost impossible.

Let me start with a fundamental reality: AI, as we're experiencing it now, is just over three years old. For everyone except AI scientists and science fiction writers, this is brand new territory. The rest of us never saw this coming. Period.

This matters because it means we're all learning in real time. There's no established playbook. There's no generation of elders who've navigated this before us. We're the first generation to face this particular challenge, and we're doing it while the technology is still evolving at breakneck speed.

I see my role as a guide. In many ways, I've been going down this trail my whole life—thinking about technology, communication, community, and how tools shape us. But in many ways, that trail wasn't possible until three short years ago. I did start on day one. I have not stopped. I've obsessively charted what's possible and terrifying about AI, and I've worked closely with Alan Hirsch and Brad Briscoe to build this.

But where is our audience? This question haunts me because the research reveals something important: we're not all in the same place. Not even close.

## The Landscape We're In

According to recent surveys, about 95% of adults have heard at least a little about AI, with 47% saying they've heard a lot—nearly double since 2022. But awareness doesn't mean understanding, and understanding doesn't mean comfort. About 62% of U.S. adults report interacting with AI at least several times a week, but that interaction ranges from casual use to deep integration. Among younger adults under 30, around one-third engage with AI several times a day. But even among regular users, there's significant variation in understanding, comfort, and concern.

The research reveals a landscape of different places:

**The Overwhelmed.** About 50% of U.S. adults say they're more concerned than excited about AI, up from 37% in 2021. Only about 10% say they're more excited than concerned. Roughly 57% rate the risks of AI for society as high or very high, while only 25% say the same about benefits. About 60% want more control over how AI is used in their lives, but only 13% feel they have a lot of control. These are people who feel the technology is moving too fast, who don't understand it, who feel powerless in the face of change.

**The Anxious.** About 49% believe AI will create significant job displacement. About 50% think AI will worsen people's ability to form meaningful relationships. About 53% believe AI will worsen creative thinking. About 67% believe AI will eliminate more jobs than it creates. These are people who see the risks clearly—job loss, erosion of human connection, loss of skills, economic disruption. They're not wrong to be concerned.

**The Disengaged.** While 95% have heard about AI, that still means 5% haven't. And even among those who have heard, many haven't engaged. They're not worried because they're not paying attention. They're not interested because it hasn't touched their lives directly yet. But that's changing rapidly.

**The Enthusiastic Early Adopters.** About one-third of adults under 30 engage with AI several times a day. These are people who've integrated AI into their daily workflows, who see the potential, who are experimenting and learning. But even among this group, there's significant variation in understanding and wisdom about how to use AI well.

**The Overconfident.** Recent research on the Dunning-Kruger effect and AI reveals something troubling: people using AI tend to overestimate their performance and understanding. AI assistance boosts actual performance but inflates self-confidence disproportionately. The classic pattern where low performers overestimate and high performers underestimate is being flattened—now, both groups overestimate when using AI. Counterintuitively, people with higher AI literacy tend to be less accurate about their performance, with more inflated self-assessments. This is the group that thinks they understand AI better than they do.

Where are we? We're all over the map. And this creates a fundamental challenge: how do we write one book that speaks to people who are overwhelmed, anxious, disengaged, enthusiastic, overconfident—all at the same time?

But here's the complicating factor: where people are is changing rapidly. Someone who's disengaged today might be overwhelmed tomorrow when AI touches their job. Someone who's enthusiastic today might become anxious tomorrow when they realize the implications. Someone who's overconfident today might become humble tomorrow when they encounter the limits of their understanding.

This rapid change makes me wonder about Dunning-Kruger more than anything. I wonder if we've even begun to learn. The research shows that AI use can lead to "cognitive offloading"—accepting AI's answers without questioning or deeply engaging. This cuts off feedback loops people rely on to calibrate how good they are. So performance might improve, but self-awareness of errors or limitations declines.

Have we even begun to learn? Or are we in the early stages of a massive overconfidence crisis? I don't know. But I suspect we're still in the early days of learning, and that the real education is just beginning.

## Why This Moment Is Different

I want to pause here and speak to something that might feel validating: movement leaders were right to be skeptical of metrics-driven content. You were right to resist the pressure to optimize for algorithms. You were right to prioritize depth over clicks, transformation over engagement, authenticity over reach.

In the old model, credibility was conferred by gatekeepers. If you wanted to be a credible voice, you needed to be published by a respected publisher, invited to speak at respected conferences, endorsed by respected institutions. When the digital revolution came—when blogs emerged, then social media, then content marketing, then SEO optimization—many movement leaders were skeptical. And that skepticism was often justified. The metrics didn't measure what mattered. The platforms rewarded extraction, not formation. The optimization pressure felt inauthentic. The gatekeepers still mattered. Movement leaders recognized that the old signals still worked, at least to some degree. And that the new signals—the metrics, the algorithms, the platform optimization—felt like a compromise.

But something has changed. The gatekeepers are losing power. AI has flooded the landscape. Your audience has changed how they discover content and leaders. The rules have changed. The old model—where gatekeepers conferred credibility, where you could build a following through books and conferences and endorsements—that model is breaking down. The new model—where credibility emerges through networks, through relationships, through visible engagement—requires different strategies. And here's what makes this moment different from the digital disruption of the 2000s and 2010s: AI has changed the cost of content creation. In the old digital model, creating content took time. AI has removed that limit. Now content can be generated at almost zero cost. Credibility signals are collapsing faster. And what's emerging as the alternative is network verification—credibility through relationships, through mutual vouching, through scenius. This is a fundamentally different mechanism than what we had before.

I'm not saying the old instincts were wrong. I'm saying the landscape has changed enough that the old instincts, applied in the same ways, might not be enough anymore. What's needed now is not abandoning your instincts, but adapting them. Holding onto what matters—depth, authenticity, transformation—while engaging with the new mechanisms for discovery and credibility. Finding ways to be visible without compromising what makes your voice valuable.

## Where We Start

Where are we? We're in different places, and those places are changing rapidly. But we're all in this together, learning in real time, trying to figure out how to navigate a technology that's reshaping everything—and doing it while the technology itself is still evolving.

The challenge is meeting people where they are while acknowledging that where they are is changing. The opportunity is creating content that can adapt, that can speak to different places, that can serve people whether they're overwhelmed or enthusiastic, anxious or overconfident, disengaged or deeply integrated.

This is why I see my role as a guide. Not because I have all the answers—I don't. Not because I've figured it all out—I haven't. But because I've been on this trail from day one, I've been charting what's possible and terrifying, and I've been working to build something that serves movement leaders well.

Where are we? We're here, together, learning. And that's where we start.

---

**Reflection Questions:**

1. Where do you find yourself on this landscape? Overwhelmed? Anxious? Enthusiastic? Somewhere else?

2. How have your instincts about digital platforms and metrics served you? What have they protected?

3. What would it look like to adapt your instincts to this new landscape, without compromising what matters?
