# Chapter 7: The Maturity Model and Why Experimentation Matters

I want to start this chapter by giving you a way to locate yourself—and to do it without shame.

We're not all in the same place with AI. Some of us are barely aware of it. Some of us are experimenting. Some of us have adopted it in specific areas. Some of us have integrated it into our workflows. Some of us are leading others through it. And there's no single right place to be. What matters is honest placement—and then movement that fits your context.

This chapter introduces a maturity model: five levels from Awareness to Leadership. It also makes the case that one level in particular—Experimentation—is crucial, and that you can't responsibly answer "should I abstain?" or "where do I draw the line?" without having experimented first. Play is prerequisite to discernment. Not a luxury. A requirement.

## The Maturity Model: Five Levels

**Level 1: Awareness.** You know AI exists. You've heard about it. You may have read articles or seen demos. But you haven't engaged with it personally in a sustained way. You're aware of the credibility crisis and the conversation, but you're not yet using AI tools in your own work.

There's no shame in being here. Many thoughtful leaders are here. The point is to be honest about it.

**Level 2: Experimentation.** You're trying things. You're using AI for low-stakes tasks—drafts, structure, variation, research. You're learning what it does well and what it doesn't. You're making mistakes. You're calibrating. You're not yet committed to adoption; you're playing. This is where learning happens.

**Level 3: Adoption.** You've decided to use AI in specific, bounded ways. You've identified use cases where AI amplifies your work without replacing it. You've set boundaries. You're transparent about usage. You're not experimenting with everything; you've adopted a few practices that work for you.

**Level 4: Integration.** AI is part of your regular workflow. You use it consistently for drafting, refinement, adaptation, variation. You've integrated it into how you create content, how you communicate, how you manage your time. It's not occasional; it's structural. But you're still in control. You're still the source. AI is still amplification, not replacement.

**Level 5: Leadership.** You're not only using AI well; you're helping others navigate it. You're guiding your team, your network, your community. You're modeling transparent, bounded, voice-preserving use. You're part of a scenius that's figuring this out together.

You might also think in terms of four paths—different dimensions or contexts (e.g., content creation, formation, leadership, community)—each of which can be at a different level. The model is a map, not a prison. The point is honest placement: where am I? Where is my organization? Where are the people I lead?

## Why Experimentation (Level 2) Is Crucial

Here's what I want you to understand: you can't responsibly answer "should I abstain?" or "where do I draw the line?" without having experimented.

If you've never used AI for drafting, you don't yet know what it feels like to refine an AI-generated paragraph until it sounds like you. If you've never used it for structure, you don't yet know where it helps and where it gets in the way. If you've never used it for research, you don't yet know how it can shorten a literature review or how it can hallucinate. You're making a decision about abstention or adoption from theory, not from experience.

Experimentation is learning about AI's benefits *and* its threats—hands-on, low-stakes. You learn what it does well (structure, expansion, variation, formatting) and what it does poorly (voice, nuance, theological depth, originality). You learn where it saves time and where it wastes it. You learn where it amplifies and where it homogenizes. That learning is the foundation for discernment. Without it, you're either refusing out of fear or adopting out of hype. With it, you can make a grounded choice.

So I want to give you permission: experiment. Play. Use AI for low-stakes tasks. Make mistakes. Calibrate. You don't have to adopt. You don't have to integrate. You don't have to lead. But you do need to experiment before you can discern well. Play is prerequisite to discernment. Not a luxury. A requirement.

## No Shame in Awareness or Experimentation

I know there's pressure to be "ahead" on AI—to be an early adopter, to be integrated, to be leading. I want to push back on that. There's no shame in being at Awareness. There's no shame in staying at Experimentation for a long time. What matters is honesty: where am I? And then: what movement fits my context?

Some leaders will stay at Experimentation for years. They'll use AI for drafts and structure and research, but they won't integrate it deeply. That's a valid choice. Some will move quickly to Adoption and Integration. That's also valid. What's not valid is pretending you're somewhere you're not, or rushing to adopt because of pressure, or refusing to experiment because of fear.

The maturity model is a map. Use it to locate yourself. Use it to decide what movement—if any—fits your context. And hold experimentation as the hinge: you can't discern well without it.

---

**Reflection Questions:**

1. Where do you locate yourself on the five levels? Where does your organization or team sit?

2. What experiments have you already run with AI? What did you learn?

3. What would low-stakes experimentation look like for you in the next month? What would you try?
