# Book Outline: Complete Point-by-Point Sequence (Revised)

**Purpose**: Single clear outline of all points the book needs to cover, in the order they should appear. This outline reflects editorial decisions about what fits, what order best serves the reader, and where new chapters are warranted.  
**Basis for decisions**: Primary audience (movement leaders who create/steward content, need discernment not recipe, permission to slow down and refuse), book’s job (formation-oriented guide, principled framework, diagnosis-then-framework), and success criteria (posture shifts, clarity, discernment enabled, decisions slowed).

---

## Editorial Decisions: What Changed and Why

**Reorder**

- **Reframe before “where we are.”** The credibility crisis and “AI as problem and solution” open the book. Then the reader gets the key reframe: *AI is not a technological challenge; it’s an anthropological problem and therefore an adaptive leadership task.* That lens comes before “where we are” and “why now,” so the reader already knows they don’t need tech expertise to lead here.
- **“Why movement leaders were right to ignore SEO”** is no longer a standalone chapter. It’s one beat inside **Where we are and why now**: why this moment is different (discoverability + network verification). The book isn’t about SEO; it’s context for “why now,” so it’s folded in.
- **“My 2025 with AI”** comes *after* the full framework (amplifier, amplification, maturity, experimentation, voice, scenius, transparency). It then works as the chapter that shows the framework in practice—the strongest use case. So: Who is speaking (story, guide) → Framework (all concepts) → **My 2025 with AI** (framework in action).

**Merge**

- **Slowing down + green/yellow/red** → one chapter, **Pace and discernment**. Same reader need: “Do I have to rush? How do I decide when to use AI and when not to?”
- **AI threats / what AI displaces + embodied leadership** → one chapter, **What AI displaces and what we protect**. One theme: what we must not lose (relationship, prayer, embodiment, formation; why embodied leadership can’t be automated).
- **Theological integrity** → folded into **What to refuse and what we’re free to do**. Theological integrity is a non-negotiable boundary; it lives with the other refusals and permissions.
- **Agents + 70/30 + spectrum and domains** → one chapter, **Practice parameters**. One job: the operational shape of “amplification” (what agents are, what ratio looks like, where we live on the spectrum, context/personalization). Avoids three short taxonomy chapters in a row.
- **Gutenberg + static vs networked** → one chapter, **From Gutenberg to networks of trust**. Historical arc and the static-vs-networked contrast are one story.

**Cut**

- No standalone SEO chapter (see above).
- No other full chapters cut; all your 11 ideas and the existing spine are preserved, reordered or merged.

**Add**

- **Where I am now** (closing chapter): Brief return to the author’s voice. Closes the loop on the preface (“this story continues”). Models “still learning”; reinforces that success for the reader is discernment and permission to slow down, not having it all figured out. New chapter.

**Result**: 21 chapters + preface, in 7 parts. Tighter sequence, fewer redundant beats, one new closing chapter.

---

## Part I: The Crisis and the Reframe

**Function**: Establish the credibility crisis, name AI as both problem and solution, and give the reader the reframe (anthropological, adaptive) so they have the right lens before “where we are.”

### Chapter 1 — The credibility crisis

- Flood of AI-generated content; breakdown of traditional credibility signals (volume, polish, presence).
- Trust collapse: default skepticism; why it matters for movement leaders specifically; why their expertise and voice are at risk.
- **AI as both problem and solution:** AI creates the crisis (infinite content, broken signals) and also provides tools that can amplify voice and efficiency. The tension: using the tool that created the problem. Why ignoring AI isn’t an option; why uncritical adoption is dangerous.

*Rationale: Collapse and problem/solution are one opening—the reader needs both before the reframe.*

### Chapter 2 — AI is not a technological challenge

- How we actually interact with AI: mostly written or verbal communication. We don’t “interface” with it technically.
- Optimizing and understanding AI does not require technological understanding. Non-technical leaders can lead here.
- **Reframe: AI is an anthropological problem.** A people problem—human flourishing, relationship, ethics, vocation, change, what it means to be human when machines mimic and augment human capacities.
- **Therefore it’s an adaptive leadership task.** Heifetz-style adaptive leadership: technical problems have known solutions; adaptive challenges require learning, loss, and change in people and culture. AI as adaptive challenge. What adaptive leadership looks like here: acknowledging loss, creating learning environments, holding tension, regulating distress, doing it in community. (Scenius and adaptive leadership connect later.)

*Rationale: One chapter for “not tech” + “anthropological” + “adaptive leadership.” The reader gets the full reframe in one place.*

### Chapter 3 — Where we are and why now

- The audience and the AI moment: we’re in different places (overwhelmed, anxious, disengaged, enthusiastic, overconfident). We’re all learning in real time; no stable playbook yet.
- **Why this moment is different:** Old model (gatekeepers conferred credibility); digital disruption (metrics replaced gatekeepers). Why movement leaders were right to reject metrics-driven content. New reality: discoverability (e.g., SEO) + network verification = credibility. So “why movement leaders were right to ignore SEO until now” is one beat here, not its own chapter.
- Sets up the need for a guide and for adaptive leadership, not technical expertise.

---

## Part II: Who Is Speaking

**Function**: Establish the author as guide and fellow traveler before the framework.

### Preface — The story

- Where you started (didn’t know anything; diagnostic reality). What it became: tool → machine → system → platform → multi-tenant vision (Alan Hirsch, Brad Briscoe, etc.). The crisis point (October; AI psychosis / 80% forever); the friend and the video; the turning point (rethinking everything, type-safety chain). What you realize now: wrong multiple times; didn’t “figure it out”; staying and still learning. Invitation: if this person didn’t know and stayed, maybe you can stay too.

### Chapter 4 — Finding a guide

- Why a guide (not a guru): someone on the trail, learning, willing to name uncertainty.
- Your role: you’ve been on this from day one; you’re still learning; you’re not selling certainty.

---

## Part III: The Framework

**Function**: Give readers the shared vocabulary and mental model. End with the framework in practice (My 2025 with AI).

### Chapter 5 — AI as credibility amplifier, not credibility faker

- When used well, AI amplifies real credibility (your voice, your network, your integrity) rather than faking it.
- Contrast: amplification vs. fabrication. Thesis in one phrase: use AI to amplify what’s real, not to simulate what isn’t.

### Chapter 6 — Amplification not replacement

- Foundational principle: AI amplifies (enhance, preserve, multiply) rather than replaces. Human voice remains primary.
- What replacement would mean and why it’s wrong. Examples: amplification vs. replacement in practice.

### Chapter 7 — The maturity model and why experimentation matters

- **Maturity model:** Five levels (Awareness → Experimentation → Adoption → Integration → Leadership). Four paths (placeholder for your path names/themes). Readers locate themselves: where am I? No shame in Awareness or Experimentation.
- **Experimentation and play (Level 2):** How it works and why it’s crucial. Learning about AI’s benefits *and* threats—hands-on, low-stakes. **Requirement before discernment:** You can’t responsibly answer “should I abstain?” or “where do I draw the line?” without having experimented. Play is prerequisite to discernment. Permission to experiment without having to adopt or integrate yet.

*Rationale: Maturity model and experimentation are one chapter—Level 2 is the hinge between “aware” and “discerning.”*

### Chapter 8 — Voice preservation as priority

- Why voice matters more than efficiency. Voice in writing vs. voice in conversation; how AI can preserve or destroy authentic voice. Technical and ethical commitment to voice preservation (no deep technical implementation in the book).

### Chapter 9 — Scenius as the credibility solution

- Scenius: collaborative genius, network verification. Why scenius creates credibility AI can’t easily fake. Network verification through human relationships; transparent relationships and intellectual lineage; emergent authority through lateral networks. Connection to adaptive leadership: we need community; scenius is the infrastructure.

### Chapter 10 — Transparency, disclosure, and trust

- Why transparency is foundational, not optional. Honest disclosure about AI usage builds trust in an untrustworthy environment. Disclosure frameworks and practices.

### Chapter 11 — My 2025 with AI

- A review of how you used AI over the year. **Centerpiece: the Movemental + Alan Hirsch project** as the single strongest use case you can give—provided it’s told well.
- What this illustrates: amplification not replacement; voice preservation; transparency; human-in-the-loop; building in public. The framework in practice.

*Rationale: This chapter closes Part III so the framework lands in a real, detailed example before we move to discernment and boundaries.*

---

## Part IV: Pace and Discernment

**Function**: Permission to slow down; a practical framework for when to abstain vs. when to accelerate; boundaries (refuse/free to do, including theological integrity).

### Chapter 12 — Pace and discernment

- **Slowing down vs. urgency vs. rushing:** Cultural pressure (FOMO, “everyone’s using AI”). Why slowing down is responsible: discernment takes time; experimentation requires space. **AI as a means of slowing down:** How AI might create space—e.g., handling administrative or drafting tasks so the leader can focus on reflection, relationship, formation—and feel free to slow down rather than speed up indiscriminately.
- **When to abstain and when to accelerate:** Green, yellow, and red lights for AI use cases. Green: use cases where AI clearly amplifies without displacing what must stay human. Yellow: use cases that require caution, context, and boundaries. Red: use cases to refuse (e.g., full automation of relationship, formation without human presence, deception). Decision aid without rigid rulebook.

*Rationale: One chapter for “do I have to rush?” and “how do I decide?”—same reader need.*

### Chapter 13 — What to refuse and what we’re free to do

- **Refuse:** Fully automated publishing; AI content without human review; voice replacement; theological content without human verification; deceptive practices; formation work without human presence.
- **Theological integrity as non-negotiable:** Why theological accuracy matters; AI assistance must align with movemental theology; human oversight and verification. What happens when theological integrity is compromised. (Folded here as a core boundary.)
- **Free/obligated to do:** Use AI for amplification; preserve voice; build scenius; be transparent; use specialized agents within boundaries; sustainable workflows. Acknowledge complexity and nuance; avoid legalistic tone.

*Rationale: Theological integrity is one of the refusals/permissions, so it lives in this chapter.*

---

## Part V: What We Protect

**Function**: Name what AI displaces and what we must protect; give the operational shape of “amplification” (agents, ratio, spectrum, context).

### Chapter 14 — What AI displaces and what we protect

- **What AI displaces:** Relationship, prayer, embodiment, spirituality, presence, slow formation. Not just “jobs”—the things that make us human and that make formation possible. Other threats: credibility fraud, homogenization of voice, dependency, overconfidence (e.g., Dunning-Kruger with AI). Name them without apocalyptic framing; hold gravity and hope.
- **Why embodied leadership cannot be automated:** What embodied leadership is; why AI cannot replace embodied presence; limits of digital formation. When AI serves embodied leadership vs. when it undermines it. The non-negotiable: human presence in formation.

*Rationale: Threats and embodied leadership are one chapter—what we must not lose.*

### Chapter 15 — Practice parameters

- **Agents as assistants, archivists, and translators:** What AI agents are (specialized tools, not synthetic personalities). Assistants (structure, expansion, variation); archivists (preserving and organizing knowledge); translators (adapting for different audiences). What agents are not.
- **The 70/30 rule and sustainable practice:** AI efficiency with human refinement; what AI does well, what humans provide; sustainable content creation (e.g., 5-hour/week); maintaining authenticity while gaining efficiency.
- **Spectrum and domains:** The spectrum of AI involvement (from none to full); where most of us will live (mostly in-between). Domains: different contexts (e.g., internal drafting vs. public teaching vs. formation) may have different green/yellow/red lights. Personalization and context as required for agentic value: why generic AI fails for formation-oriented work.

*Rationale: One chapter for the operational shape of amplification—agents, ratio, spectrum, context—so we don’t have three short taxonomy chapters.*

---

## Part VI: Practice

**Function**: Apply the framework to content creation and formation; give a humane, non-technical way to work with AI (prompting as communication).

### Chapter 16 — AI and content creation

- The spectrum: from no AI use to full AI generation, and the mostly in-between space we’re likely to inhabit. How it works across the spectrum: transparency, disclosure, voice preservation, human review. What “in-between” looks like in practice. Transparency as part of content practice, not an add-on.

### Chapter 17 — AI and formation and leadership

- How AI serves or undermines formation: content that supports formation vs. content that substitutes for it. How AI serves or undermines leadership: when it frees leaders for relationship and presence; when it displaces them. Formation happens offline; AI can support the content that serves that offline work, or it can undermine it. Integration with scenius, embodied leadership, what to refuse.

### Chapter 18 — Everything I know about “prompting”

- **The anti-prompt-engineering guide:** Treating AI humanely and communicating well with it. Not a technical manual: no jargon, no “optimization” as the goal. Rather: clarity, specificity, iteration, and treating the system as something you’re in conversation with—not something you “engineer.” Practical wisdom: how to ask, how to refine, how to stay in the driver’s seat. Fits the book’s claim that interacting with AI is mostly written/verbal communication and doesn’t require tech expertise.

---

## Part VII: The Long Arc

**Function**: Place the current moment in a longer story; close with vision and with the author’s voice (still learning).

### Chapter 19 — From Gutenberg to networks of trust

- Historical progression: Gutenberg (democratized text); mass media (gatekeeping); digital disruption (fragmented credibility); AI (credibility crisis and scenius as response). Networks of trust as the future of credibility.
- **Static publishing vs. networked credibility:** Static: one-way, isolated, individual. Networked: interconnected, verified, collective. Why static publishing fails in the AI age; how networked credibility creates sustainable authority. The shift from individual to scenius.

*Rationale: History and static-vs-networked are one chapter—one long arc.*

### Chapter 20 — Content that moves

- What “content that moves” means: transformation, not just engagement. Ethical shift, not marketing trick. Difference between content that moves (formation, authenticity) and content that manipulates. How AI can serve movemental content vs. undermine it. Closing vision: the future belongs to leaders who embed their work in networks of verified humans while using AI as amplification, not replacement.

### Chapter 21 — Where I am now

- **New chapter.** Brief return to the author’s voice. Close the loop on the preface: this story continues; I’m still learning; I’m still wrong about some things. What I’m holding to; what I’m still figuring out. Invitation: you don’t have to have it all figured out either. Stay. Discern. Slow down. We’re in this together.

*Rationale: The book’s success is partly the reader feeling permission to slow down and not have it all figured out. The author modeling “still learning” at the end reinforces that. It also honors the preface’s promise that the story continues.*

---

## Summary: Your 11 Ideas Mapped to the Revised Outline

| # | Your idea | Chapter(s) |
|---|-----------|------------|
| 1 | AI as anthropological/adaptive leadership problem (not technological); Heifetz | **Ch2** (AI is not a technological challenge) |
| 2 | AI as credibility amplifier, not faker | **Ch5** |
| 3 | My 2025 with AI / Movemental + Alan Hirsch use case | **Ch11** |
| 4 | Maturity model (4 paths, 5 levels) | **Ch7** |
| 5 | Experimentation & play (Level 2); prerequisite to abstention/discernment | **Ch7** |
| 6 | Slowing down vs urgency vs rushing; AI as means of slowing down | **Ch12** |
| 7 | When to abstain / when to accelerate; green, yellow, red lights | **Ch12** |
| 8 | AI threats; what AI displaces (relationship, prayer, embodiment, spirituality) | **Ch14** |
| 9 | AI & content creation; spectrum; transparency | **Ch16** |
| 10 | AI & formation & leadership | **Ch17** |
| 11 | Everything I know about prompting (anti-prompt-engineering; humane communication) | **Ch18** |

---

## Chapter List at a Glance

| # | Title |
|---|--------|
| — | Preface: The story |
| 1 | The credibility crisis |
| 2 | AI is not a technological challenge |
| 3 | Where we are and why now |
| 4 | Finding a guide |
| 5 | AI as credibility amplifier, not credibility faker |
| 6 | Amplification not replacement |
| 7 | The maturity model and why experimentation matters |
| 8 | Voice preservation as priority |
| 9 | Scenius as the credibility solution |
| 10 | Transparency, disclosure, and trust |
| 11 | My 2025 with AI |
| 12 | Pace and discernment |
| 13 | What to refuse and what we’re free to do |
| 14 | What AI displaces and what we protect |
| 15 | Practice parameters |
| 16 | AI and content creation |
| 17 | AI and formation and leadership |
| 18 | Everything I know about “prompting” |
| 19 | From Gutenberg to networks of trust |
| 20 | Content that moves |
| 21 | Where I am now |

**Total: 21 chapters + preface.**

---

**End of outline.**  
This sequence is the target order for the book’s argument. Rationale for each merge, reorder, cut, and new chapter is above; the 11 ideas are preserved and mapped to the revised chapters.
