# Author Transcript: Origin, Scope, and Crisis
## Faithful Documentation Capture

**Date**: January 2026  
**Source**: Author's spoken reflection  
**Status**: Documentation - Not Draft  
**Editing**: Light punctuation, paragraphing, removal of verbal stutters only

---

## Editorial Note

This is a faithful, edited transcript of what the author actually said, organized for clarity and documentation, with:

- No reframing of intent
- No business spin
- No smoothing away uncertainty
- No rewriting into a different voice
- No resolving tensions you intentionally left open

Edits are limited to:
- Light punctuation
- Paragraphing
- Removing verbal stutters and false starts
- Clarifying sentence boundaries

Where the author explicitly signaled "this needs development later" or "I don't know how to say this yet", this is preserved as-is, sometimes with a minimal bracketed note like [needs development] to mark it, not to solve it.

**This is a documentation capture, not a draft.**

---

## Faithful Transcript (Edited for Clarity, Not Rewritten)

### On the origin and scope of the project

I give the date that the project began, all of the project features in scope, and that was basically all work that had been accomplished since that date. Then I do the work of translating that—not only for a non-technical audience—but I'm also basically saying: this is how much someone would charge for that amount of work, how many hours it would take.

And I want to acknowledge that this is not a story about a superhuman programmer. In fact, I did not know anything.

Now this is interesting, and I'll talk about it in a business sense later, but the truth is: I did not know anything.

So the question is, if you didn't know anything, why did you believe you could do this?

I believed I could do this because I extrapolated from what I was experiencing, what I knew about myself, and my capacity to learn—to know how to solve problems I didn't understand or didn't know how to solve that day. I paired that with what I knew about AI as the technology existed at that moment, and what it could help me figure out.

And then in some way that belief grew during the project because I ended up using a technology I didn't have when I started.

But when I started, what I had was the knowledge that I didn't know how to do this—and that I had never done it before.

### On prior experience and the false extrapolation

Specifically, what I had never done before was build a database of any kind.

As a full-stack developer, I had built one or two React apps—maybe three. One of them I launched on the iOS App Store and Android. That process went very quickly. About four weeks. No—actually, a week from start to finish.

What we'll explore is how I made the mistake of extrapolating a front-end-only app to the far more complex process of designing what became a full system.

This is interesting because the scope of the project evolved rapidly as well.

As I said previously, it went from:

- a tool
- to a machine
- to a system
- to a comprehensive vision for a senior leader using a technology platform

It was supposed to be for Alan Hirsch.

Along the way, we realized we could link Alan Hirsch and Brad Briscoe together.

So if we translate the work done into a pre-AI frame and ask, "What happened?"—the truth of what happened is crucial.

### On delusion, time, and the crisis point

Essentially, I now know I was operating under a delusion—if the delusion was that I knew how to do this on my current trajectory.

There was also a mistake—maybe not a delusion—of not knowing how much time it would take.

That's interesting when you consider how much time it would have taken.

This is where I need to weave the narrative. Part of it is that right now, for myself, I may even be defensive. I'm documenting the scope of the work done and trying to translate it afresh.

Because if you don't understand the scope of the work done, then you don't understand how AI is changing the world. Any of it.

### On the breaking point and outside perspective

Around late October, I hit a point of internal crisis.

I had the internal conviction that I might have succumbed to what I understood as AI psychosis—the delusion that I was close to finishing something that would only ever be 80% complete and would fail.

I reached out to the one and only friend I have who is a software developer.

Not to ask for help—but to say, "Look what I'm building."

Probably also to pay lip service to, "It's a little hard," but I don't think I did. I think I just thought, "I'm building this, and I'll get there."

He didn't say much. We talked. He shared a video. It seemed random—just supportive. "Good job." And then, "Here are some cool videos about building with AI."

But I remember watching that video and realizing I was beginning to be concerned that no matter how many times I tried the approach I was taking, it wasn't working.

I was trying that approach across six or seven applications—CRM, front ends—moving fast, because the front end was so fast.

### On the pivot: system thinking and the type safety chain

Over maybe a week—dated around 10/17 or 10/27, about a month and a half into the project—I began working with AI to design a system that would solve the technological problems in a way AI could actually help me.

That led to the creation of what I now call the type safety chain.

This is important because the project, when conceived not only as a technological project but as a business vision and partnership, has to tell a story of AI's power and potential—for good and bad—alongside a human story.

A group of people working it out together.

I shared everything with them during that time, as I had since day one.

### On multiplication and multi-tenancy

What began as an app to share Alan's work evolved into:

- an app that showcased AI
- then one that demonstrated it
- then one that prophetically modeled it

Which evolved into the realization that I already wanted to do this for Brad.

Why not connect them?

Why not use the same platform in a multi-tenant way?

If front-end apps take a short amount of time, and the hard work is the system underneath, then building the first app has little to do with the time it takes to build the second.

There are complexities there, but the vision was always about multiplication.

That vision changed the timeline because it made everything more adaptive.

### On learning while building and evolving vision

So now you're talking about a person who had to learn everything they were doing every day—while adapting that learning to an evolving business vision.

And doing that while also learning how to work agentically with AI.

### On accountability, discipleship, and AI

In sharing this story, I'm also doing the one thing I think can protect us from misusing the world's most powerful and exponentially improving technology.

We are going to have to connect.

To the extent that we are using AI, we're going to have to share how we're using it.

We're going to have to make AI accountability a feature of our lives.

That shouldn't shock anyone who takes a non-dualistic approach to discipleship.

This is a discipleship issue.

If the internet, social media, and pornography are discipleship issues—and they are—then AI is going to be the technological discipleship issue of the rest of our lives.

### On unprecedented ignorance

We did not ask for this.

We did not see it coming.

We are beginners working with a technology no one understands.

For the first time in history, we are dealing with a technology that no humans understand—not just most humans.

### On guiding through the unknowable

In positioning myself as a guide, I knew I was in unprecedented territory.

How do you guide people through the unknowable as it intersects with daily life?

I did this because I recognized what I was already becoming—and what I now understand I was gifted at understanding.

[This needs careful development: what does AI giftedness actually entail?]

### On the credibility crisis

I began conceiving Movemental in January 2025 for a January 2026 audience.

An audience that had heard of AI, tried it, and was now vaguely realizing they needed to understand it better.

And they do.

I remember thinking I'd reassure them with "beginner's mind."

But now, just a year later, AI expertise is growing disproportionately.

We are about to have an AI credibility crisis.

That's not good.

It's not good when:

- no one understands the technology
- it is immensely powerful
- and people think they've figured it out

Dunning–Kruger on steroids.

Including me.

### On being wrong—and what changed everything

I built this thinking I knew something.

I was wrong.

What I did next is changing my life again.

I refused to stop experimenting—even when overwhelmed and confused.

And I was willing to reconsider everything in light of new information shared in human relationship.

### Closing reflection

To alter Robert Frost:

I took the road less traveled.
I did it with friends.
And that has made all the difference.

The road less traveled with AI will be the thoughtful one.

The discerning one.

The one that abstains in some ways and integrates in others.

The question I'm trying to answer is how.

And I'm doing it consciously for my people—my tribe.

It's good to be back.

---

**Document Status**: Faithful Transcript - Documentation Only  
**Last Updated**: January 2026  
**Related Documents**:
- `chapter-the-story.md` - Narrative retelling based on this transcript
- `chapter-finding-an-ai-expert.md` - Related chapter on expertise
- `chapter-aa-where-we-are-processed.md` - Related chapter on audience
