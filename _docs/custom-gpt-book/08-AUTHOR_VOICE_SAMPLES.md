# Author Voice Samples and Transcript Analysis (Consolidated)

---

# Transcript Analysis: How This Functions in the Book Narrative
## Integration and Function Analysis

**Date**: January 2026  
**Purpose**: Analyze how the author transcript relates to the book's narrative structure and themes  
**Status**: Analysis Document

---

## Overview

This transcript provides the raw, unfiltered source material for "The Story" chapter. It contains crucial details, emotional realities, and conceptual threads that both support and expand the narrative retelling. This analysis examines how it functions in conjunction with the rest of the book.

---

## Key Additions and Expansions

### 1. The Specific Date and Technical Details

**Transcript**: "Over maybe a week—dated around 10/17 or 10/27, about a month and a half into the project"

**Function**: Provides concrete timeline that the narrative chapter generalizes ("mid-October, maybe late October"). This specificity could strengthen the narrative if integrated, or the generalization could be preserved to maintain the sense of uncertainty.

**Connection to Book**: The timeline precision vs. uncertainty reflects the book's theme about operating in unprecedented territory where exact dates matter less than the reality of the moment.

### 2. The Friend and the Video

**Transcript**: "I reached out to the one and only friend I have who is a software developer... He shared a video... I remember watching that video and realizing I was beginning to be concerned that no matter how many times I tried the approach I was taking, it wasn't working."

**Function**: This is a crucial detail missing from the narrative chapter. The external perspective, the video, the realization—this is the actual turning point moment, not just the abstract "rethinking everything."

**Connection to Book**: This connects to themes of:
- **Relational accountability** (Chapter on discipleship/AI accountability)
- **External perspective** (Chapter on finding an AI expert/guide)
- **Learning through relationship** (Central theme throughout)

**Recommendation**: This should be integrated into the narrative chapter. It's the concrete moment of crisis and realization, not just the abstract concept.

### 3. The Six or Seven Applications

**Transcript**: "I was trying that approach across six or seven applications—CRM, front ends—moving fast, because the front end was so fast."

**Function**: Expands the "other systems" context. The narrative mentions "a CRM, an LMS" but the transcript reveals the scope: "six or seven applications." This is important for understanding the scale of what was happening.

**Connection to Book**: This detail supports the claim "If you don't understand the scope of what happened here, you won't understand how AI is changing the world." The scale matters.

### 4. AI Psychosis

**Transcript**: "I had the internal conviction that I might have succumbed to what I understood as AI psychosis—the delusion that I was close to finishing something that would only ever be 80% complete and would fail."

**Function**: This is a powerful concept that appears in the narrative as "AI-induced delusion" but the transcript's "AI psychosis" is more specific and could be developed as a concept.

**Connection to Book**: This connects to:
- **Dunning-Kruger concerns** (Chapter AA: "Where We Are")
- **Overconfidence crisis** (Chapter AA)
- **The credibility crisis** (Chapter 1, and this transcript's section on credibility crisis)

**Recommendation**: "AI psychosis" could be developed as a concept in a later chapter, or integrated into the narrative chapter as the specific fear the author experienced.

### 5. The Evolution: Showcase → Demonstrate → Prophetically Model

**Transcript**: "What began as an app to share Alan's work evolved into: an app that showcased AI, then one that demonstrated it, then one that prophetically modeled it."

**Function**: This is a more nuanced evolution than the narrative's "tool → machine → system → platform." This shows the conceptual evolution, not just the technical scope.

**Connection to Book**: This connects to:
- **The book's own function** (showcasing, demonstrating, prophetically modeling AI use)
- **The Movemental platform's purpose** (not just a tool, but a prophetic model)
- **The author's calling** (not just building, but modeling)

**Recommendation**: This could be integrated into the narrative chapter or developed as a separate thread about the vision's evolution.

### 6. Discipleship and AI Accountability

**Transcript**: "This is a discipleship issue. If the internet, social media, and pornography are discipleship issues—and they are—then AI is going to be the technological discipleship issue of the rest of our lives."

**Function**: This is a major thematic statement that appears in the transcript but isn't fully developed in the narrative chapter. It's a forward-looking claim that sets up later chapters.

**Connection to Book**: This connects to:
- **Future chapter on AI discipleship** (mentioned in transcript)
- **The relational accountability theme** (sharing with Alan, Brad, others)
- **The book's theological framework** (formation, not just information)

**Recommendation**: This should be flagged for a dedicated chapter or section on AI as a discipleship issue. It's too important to leave undeveloped.

### 7. AI Giftedness

**Transcript**: "I did this because I recognized what I was already becoming—and what I now understand I was gifted at understanding. [This needs careful development: what does AI giftedness actually entail?]"

**Function**: The author explicitly flags this for development. This is a concept that appears in other chapters (the "Finding an AI Expert" chapter mentions it) and needs careful theological and anthropological development.

**Connection to Book**: This connects to:
- **The "Finding an AI Expert" chapter** (the criteria for guidance)
- **Theological anthropology** (image of God, calling, stewardship)
- **The author's own positioning** (guide, not expert)

**Recommendation**: This needs a dedicated section or chapter. The author's note indicates it requires careful development to avoid self-aggrandizement while acknowledging the reality of the moment.

### 8. The Credibility Crisis Timeline

**Transcript**: "I began conceiving Movemental in January 2025 for a January 2026 audience... But now, just a year later, AI expertise is growing disproportionately. We are about to have an AI credibility crisis."

**Function**: This provides the timeline for the credibility crisis concern. The author conceived the project for a 2026 audience, but by 2026, the landscape had already changed. This is meta-commentary on the speed of change.

**Connection to Book**: This connects to:
- **Chapter 1: The Credibility Collapse** (the crisis is happening)
- **Chapter AA: Where We Are** (the audience is in different places)
- **The book's own timeliness** (written in real-time about real-time change)

**Recommendation**: This could be integrated into the opening chapters to show how rapidly the landscape is changing, even as the book is being written.

### 9. "Dunning-Kruger on Steroids. Including me."

**Transcript**: Direct admission that the author himself is subject to the overconfidence problem.

**Function**: This is crucial for the book's credibility. The author doesn't position himself outside the problem—he's inside it, learning, wrong, but staying.

**Connection to Book**: This connects to:
- **Chapter AA's concern about overconfidence**
- **The "Finding an AI Expert" chapter** (the author's own criteria)
- **The story chapter** (being wrong multiple times)

**Recommendation**: This admission should be more prominent in the narrative chapter. It's the key to the book's credibility—not "I figured it out" but "I'm wrong, and I'm staying anyway."

### 10. The Frost Alteration

**Transcript**: "To alter Robert Frost: I took the road less traveled. I did it with friends. And that has made all the difference."

**Function**: This is a powerful closing that could work as a chapter ending or book ending. It captures the relational, collaborative nature of the work.

**Connection to Book**: This connects to:
- **Scenius** (collaborative genius, not individual)
- **Relational accountability** (doing it with friends)
- **The book's closing** (wherever that lands)

**Recommendation**: This could be a powerful chapter ending or even book ending. It's simple, profound, and captures the essence of what matters.

---

## How This Transcript Functions in the Book

### 1. As Source Material

The transcript is the raw material from which "The Story" chapter is crafted. It provides:
- **Specific details** that can be integrated or generalized
- **Emotional reality** that must be preserved
- **Conceptual threads** that need development in later chapters
- **Timeline precision** that can inform the narrative

### 2. As Thematic Foundation

The transcript establishes themes that run throughout the book:
- **Unprecedented ignorance** → "Where We Are" chapter
- **AI psychosis/delusion** → Credibility crisis chapters
- **Discipleship and accountability** → Future chapters on formation
- **AI giftedness** → "Finding an AI Expert" chapter
- **Relational learning** → Scenius and credibility chapters

### 3. As Credibility Anchor

The transcript's honesty provides credibility for the entire book:
- **Admission of ignorance** ("I did not know anything")
- **Admission of delusion** ("I was operating under a delusion")
- **Admission of being wrong** ("I built this thinking I knew something. I was wrong.")
- **Admission of overconfidence** ("Dunning-Kruger on steroids. Including me.")

This honesty is the book's greatest asset—not expertise, but persistent grappling in relationship.

### 4. As Forward-Looking Threads

The transcript flags concepts that need development:
- **AI giftedness** → Needs careful theological development
- **Discipleship and AI** → Needs dedicated chapter/section
- **AI accountability** → Needs practical framework
- **Credibility crisis** → Already developed, but timeline adds urgency

### 5. As Meta-Commentary

The transcript itself becomes evidence of the book's claims:
- **Speed of change** (conceived for 2026, but 2026 is already different)
- **Unprecedented territory** (no one understands, including the author)
- **Relational accountability** (sharing the story, the process, the uncertainty)
- **Learning in real-time** (the transcript shows the author still figuring it out)

---

## Integration Recommendations

### Immediate Integration (Narrative Chapter)

1. **The friend and the video** — This is the concrete turning point. Should be in the narrative.
2. **The six or seven applications** — Expands the scope reality. Should be integrated.
3. **AI psychosis** — More specific than "AI-induced delusion." Could be integrated or developed separately.
4. **"Dunning-Kruger on steroids. Including me."** — This admission should be more prominent.

### Development for Later Chapters

1. **Discipleship and AI** — Needs dedicated chapter or major section
2. **AI giftedness** — Needs careful theological development (flagged by author)
3. **AI accountability** — Needs practical framework
4. **The evolution: showcase → demonstrate → prophetically model** — Could be a thread about the book's own purpose

### Preservation as Documentation

1. **Keep the transcript as-is** — It's valuable as raw source material
2. **Reference it in bracketed notes** — When narrative chapter needs expansion
3. **Use it for future chapters** — When developing the flagged concepts

---

## How This Strengthens the Book

### 1. Credibility Through Honesty

The transcript's unfiltered honesty is the book's greatest strength. It shows:
- The author doesn't have it figured out
- The author is wrong, learning, staying
- The author is inside the problem, not above it

This is exactly what the book claims is needed: not experts, but guides who are learning alongside.

### 2. Thematic Coherence

The transcript establishes themes that weave throughout:
- **Unprecedented territory** → Every chapter
- **Relational learning** → Scenius, credibility, discipleship
- **Being wrong and staying** → The story, the expert chapter, the closing
- **Discipleship issue** → Formation chapters, accountability chapters

### 3. Forward Movement

The transcript doesn't resolve—it opens questions:
- What is AI giftedness?
- How do we make AI accountability a feature of our lives?
- How do we guide through the unknowable?
- How do we navigate the credibility crisis?

These questions drive the book forward, not backward-looking answers.

### 4. Meta-Authenticity

The transcript itself models what the book teaches:
- **Transparency** (sharing the process, not just the product)
- **Vulnerability** (admitting ignorance, delusion, being wrong)
- **Relational accountability** (doing it with friends, sharing everything)
- **Learning in real-time** (still figuring it out, still wrong)

The book practices what it preaches.

---

## Conclusion

This transcript functions as:
1. **Source material** for the narrative chapter
2. **Thematic foundation** for the entire book
3. **Credibility anchor** through honest admission
4. **Forward-looking threads** for later development
5. **Meta-commentary** on the book's own claims

It's not just documentation—it's the DNA of the book. The narrative chapter should preserve its honesty, integrate its crucial details, and flag its forward-looking concepts for development.

The transcript's greatest value is its unfiltered reality: the author didn't know, was wrong, stayed anyway, and is still learning. That's the story the book needs to tell, and this transcript tells it without sanitization.

---

**Document Status**: Analysis Complete  
**Last Updated**: January 2026  
**Related Documents**:
- `author-transcripts/transcript-origin-scope-crisis.md` - The transcript itself
- `chapter-the-story.md` - Narrative chapter based on this transcript
- `human-in-the-loop-narrative-synthesis-method.md` - Method for integration

---

# Author Transcript: Origin, Scope, and Crisis
## Faithful Documentation Capture

**Date**: January 2026  
**Source**: Author's spoken reflection  
**Status**: Documentation - Not Draft  
**Editing**: Light punctuation, paragraphing, removal of verbal stutters only

---

## Editorial Note

This is a faithful, edited transcript of what the author actually said, organized for clarity and documentation, with:

- No reframing of intent
- No business spin
- No smoothing away uncertainty
- No rewriting into a different voice
- No resolving tensions you intentionally left open

Edits are limited to:
- Light punctuation
- Paragraphing
- Removing verbal stutters and false starts
- Clarifying sentence boundaries

Where the author explicitly signaled "this needs development later" or "I don't know how to say this yet", this is preserved as-is, sometimes with a minimal bracketed note like [needs development] to mark it, not to solve it.

**This is a documentation capture, not a draft.**

---

## Faithful Transcript (Edited for Clarity, Not Rewritten)

### On the origin and scope of the project

I give the date that the project began, all of the project features in scope, and that was basically all work that had been accomplished since that date. Then I do the work of translating that—not only for a non-technical audience—but I'm also basically saying: this is how much someone would charge for that amount of work, how many hours it would take.

And I want to acknowledge that this is not a story about a superhuman programmer. In fact, I did not know anything.

Now this is interesting, and I'll talk about it in a business sense later, but the truth is: I did not know anything.

So the question is, if you didn't know anything, why did you believe you could do this?

I believed I could do this because I extrapolated from what I was experiencing, what I knew about myself, and my capacity to learn—to know how to solve problems I didn't understand or didn't know how to solve that day. I paired that with what I knew about AI as the technology existed at that moment, and what it could help me figure out.

And then in some way that belief grew during the project because I ended up using a technology I didn't have when I started.

But when I started, what I had was the knowledge that I didn't know how to do this—and that I had never done it before.

### On prior experience and the false extrapolation

Specifically, what I had never done before was build a database of any kind.

As a full-stack developer, I had built one or two React apps—maybe three. One of them I launched on the iOS App Store and Android. That process went very quickly. About four weeks. No—actually, a week from start to finish.

What we'll explore is how I made the mistake of extrapolating a front-end-only app to the far more complex process of designing what became a full system.

This is interesting because the scope of the project evolved rapidly as well.

As I said previously, it went from:

- a tool
- to a machine
- to a system
- to a comprehensive vision for a senior leader using a technology platform

It was supposed to be for Alan Hirsch.

Along the way, we realized we could link Alan Hirsch and Brad Briscoe together.

So if we translate the work done into a pre-AI frame and ask, "What happened?"—the truth of what happened is crucial.

### On delusion, time, and the crisis point

Essentially, I now know I was operating under a delusion—if the delusion was that I knew how to do this on my current trajectory.

There was also a mistake—maybe not a delusion—of not knowing how much time it would take.

That's interesting when you consider how much time it would have taken.

This is where I need to weave the narrative. Part of it is that right now, for myself, I may even be defensive. I'm documenting the scope of the work done and trying to translate it afresh.

Because if you don't understand the scope of the work done, then you don't understand how AI is changing the world. Any of it.

### On the breaking point and outside perspective

Around late October, I hit a point of internal crisis.

I had the internal conviction that I might have succumbed to what I understood as AI psychosis—the delusion that I was close to finishing something that would only ever be 80% complete and would fail.

I reached out to the one and only friend I have who is a software developer.

Not to ask for help—but to say, "Look what I'm building."

Probably also to pay lip service to, "It's a little hard," but I don't think I did. I think I just thought, "I'm building this, and I'll get there."

He didn't say much. We talked. He shared a video. It seemed random—just supportive. "Good job." And then, "Here are some cool videos about building with AI."

But I remember watching that video and realizing I was beginning to be concerned that no matter how many times I tried the approach I was taking, it wasn't working.

I was trying that approach across six or seven applications—CRM, front ends—moving fast, because the front end was so fast.

### On the pivot: system thinking and the type safety chain

Over maybe a week—dated around 10/17 or 10/27, about a month and a half into the project—I began working with AI to design a system that would solve the technological problems in a way AI could actually help me.

That led to the creation of what I now call the type safety chain.

This is important because the project, when conceived not only as a technological project but as a business vision and partnership, has to tell a story of AI's power and potential—for good and bad—alongside a human story.

A group of people working it out together.

I shared everything with them during that time, as I had since day one.

### On multiplication and multi-tenancy

What began as an app to share Alan's work evolved into:

- an app that showcased AI
- then one that demonstrated it
- then one that prophetically modeled it

Which evolved into the realization that I already wanted to do this for Brad.

Why not connect them?

Why not use the same platform in a multi-tenant way?

If front-end apps take a short amount of time, and the hard work is the system underneath, then building the first app has little to do with the time it takes to build the second.

There are complexities there, but the vision was always about multiplication.

That vision changed the timeline because it made everything more adaptive.

### On learning while building and evolving vision

So now you're talking about a person who had to learn everything they were doing every day—while adapting that learning to an evolving business vision.

And doing that while also learning how to work agentically with AI.

### On accountability, discipleship, and AI

In sharing this story, I'm also doing the one thing I think can protect us from misusing the world's most powerful and exponentially improving technology.

We are going to have to connect.

To the extent that we are using AI, we're going to have to share how we're using it.

We're going to have to make AI accountability a feature of our lives.

That shouldn't shock anyone who takes a non-dualistic approach to discipleship.

This is a discipleship issue.

If the internet, social media, and pornography are discipleship issues—and they are—then AI is going to be the technological discipleship issue of the rest of our lives.

### On unprecedented ignorance

We did not ask for this.

We did not see it coming.

We are beginners working with a technology no one understands.

For the first time in history, we are dealing with a technology that no humans understand—not just most humans.

### On guiding through the unknowable

In positioning myself as a guide, I knew I was in unprecedented territory.

How do you guide people through the unknowable as it intersects with daily life?

I did this because I recognized what I was already becoming—and what I now understand I was gifted at understanding.

[This needs careful development: what does AI giftedness actually entail?]

### On the credibility crisis

I began conceiving Movemental in January 2025 for a January 2026 audience.

An audience that had heard of AI, tried it, and was now vaguely realizing they needed to understand it better.

And they do.

I remember thinking I'd reassure them with "beginner's mind."

But now, just a year later, AI expertise is growing disproportionately.

We are about to have an AI credibility crisis.

That's not good.

It's not good when:

- no one understands the technology
- it is immensely powerful
- and people think they've figured it out

Dunning–Kruger on steroids.

Including me.

### On being wrong—and what changed everything

I built this thinking I knew something.

I was wrong.

What I did next is changing my life again.

I refused to stop experimenting—even when overwhelmed and confused.

And I was willing to reconsider everything in light of new information shared in human relationship.

### Closing reflection

To alter Robert Frost:

I took the road less traveled.
I did it with friends.
And that has made all the difference.

The road less traveled with AI will be the thoughtful one.

The discerning one.

The one that abstains in some ways and integrates in others.

The question I'm trying to answer is how.

And I'm doing it consciously for my people—my tribe.

It's good to be back.

---

**Document Status**: Faithful Transcript - Documentation Only  
**Last Updated**: January 2026  
**Related Documents**:
- `chapter-the-story.md` - Narrative retelling based on this transcript
- `chapter-finding-an-ai-expert.md` - Related chapter on expertise
- `chapter-aa-where-we-are-processed.md` - Related chapter on audience
