# MANUSCRIPT — Part VI: Practice (Chapters 16–18)

---

# Chapter 16: AI and Content Creation

I want to start this chapter by being practical about content creation: the spectrum of AI use, the mostly in-between space we're likely to inhabit, and how transparency and voice preservation work across that spectrum.

## The Spectrum of AI Use in Content Creation

The spectrum runs from no AI use to full AI generation. At one end, you create everything yourself. At the other end, AI generates content and you approve it (that's replacement; for most movement leaders, that's a red light). In between, there's a wide range: AI helps with structure, drafting, refinement, variation. You provide the ideas, the voice, the insight. AI amplifies. You remain the source. Most of us will live in that in-between space.

## What "In-Between" Looks Like in Practice

**Drafting:** You have an idea. You write a rough draft—or you speak it and have it transcribed. AI helps you structure it, expand it, refine it. You revise. You own the voice and the insight. AI amplified; you provided.

**Variation:** You create a piece of content. AI helps you adapt it for different audiences, formats, or contexts. The core content is yours. The variations are yours to approve. Transparency: "I used AI to help me adapt this; the core content and voice are mine."

**Transparency as part of content practice:** Transparency isn't an add-on. When you publish, you're clear about when and how AI was involved. That builds trust. It protects credibility.

**Human review:** Whatever the ratio, content that carries your voice or your theology gets human review. You don't publish AI output unedited. You refine. You verify. You own it.

Different content types may sit at different points on the spectrum. Internal drafts might involve more AI assistance. Public teaching might involve more human refinement. Content that touches formation might sit closer to the "no AI" end. The spectrum is a map. You decide where each type of content sits—and you stay transparent about it.

---

**Reflection Questions:**

1. Where do your current content types sit on the spectrum?

2. What would "in-between" look like for you in practice?

3. How do you build transparency into your content practice?

---

# Chapter 17: AI and Formation and Leadership

Formation happens offline. Spiritual formation, discipleship, character development, theological maturity—these are fundamentally embodied processes that require presence, relationship, time, and the slow work of the Spirit in real lives and real communities. No amount of digital content, no matter how well-crafted or AI-enhanced, can replace the embodied work of formation.

But that invites a question: What might happen online that supports offline formation—both our own formation and the formation of our audiences?

## When AI Serves Formation and When It Undermines It

AI serves formation when it amplifies authentic voice, preserves theological integrity, and creates content that points people toward embodied community and real transformation. AI undermines formation when it replaces human presence, creates the illusion of relationship, or produces content that substitutes for the slow work of discipleship.

Formation requires elements that are fundamentally human: relationship with a mentor or community, accountability, the slow accumulation of wisdom through experience, the work of the Spirit in transforming character. AI cannot provide these. But AI can support the content that formation requires: clear teaching, accessible resources, personalized learning materials, culturally relevant adaptations.

The danger is when AI-assisted content creates the illusion that formation can happen through consumption alone. Formation isn't consumption—it's transformation. And transformation requires the offline elements that AI cannot provide: presence, relationship, accountability, time.

## When AI Serves Leadership and When It Undermines It

AI serves leadership when it frees leaders for relationship and presence—handling logistics, drafting, structure so that leaders can focus on what only they can do: be present, build relationship, form people. AI undermines leadership when it displaces leaders—when it creates the appearance of presence without actual presence, when it substitutes for relationship.

Formation happens offline. AI can support the content that serves that offline work—teaching series that small group leaders use, theologically sound resources that mentors reference, culturally adapted curriculum that local leaders use. In these cases, AI amplifies the leader's voice and expertise. AI undermines formation when it creates content that substitutes for the offline work—generic spiritual content consumed without community, polished materials that create the illusion of expertise without substance.

For your own formation: AI can help you access resources and organize your learning. But your formation still happens offline. For your audiences' formation: AI can help you create content that serves their discipleship. But the content serves the formation; it doesn't create it. Formation happens when people engage with the content in the context of offline community. The distinction: content that supports formation vs. content that replaces it.

---

**Reflection Questions:**

1. Where have you seen AI serve formation? Where have you seen it undermine formation?

2. How does the content you create point people toward embodied community—or away from it?

3. What would it look like for you to use AI to support formation without substituting for it?

---

# Chapter 18: Everything I Know About "Prompting"

I want to start this chapter by saying what this is not: this is not a prompt-engineering guide. I'm not going to give you formulas to "optimize" your prompts for maximum output. I'm not going to treat AI as a system you engineer. I'm going to treat it as something you're in conversation with—and the way you "prompt" is really just the way you communicate. Clarity, specificity, iteration, and respect go a long way. You don't need to be technical. You need to be clear.

## The Anti-Prompt-Engineering Approach

Prompt engineering often sounds like: use these exact phrases, structure your request this way, optimize for token efficiency, chain your prompts in this sequence. That approach treats AI as a system to be engineered—something you hack, something you optimize. I want to push back. The way we actually interact with AI is mostly written or verbal communication. We're not interfacing with it technically. We're talking to it. So the skills that matter are the skills you already have: clarity, specificity, the ability to refine and iterate, the ability to judge whether a response is helpful or off.

Treating AI humanely means: you're in conversation. You're not engineering a system. You're asking a question, giving context, refining when the answer isn't right, and staying in the driver's seat. You're the one with the insight. You're the one with the voice. AI is helping you think, not thinking for you.

## What Actually Helps: Clarity, Specificity, Iteration

**Clarity:** Say what you want. Not in jargon. In plain language. "Help me structure this section" is clearer than "Optimize the structural coherence of this textual unit." "I need this to sound like me—here's a sample of my writing" is clearer than "Apply voice preservation parameters." The clearer you are, the more useful the response.

**Specificity:** Give context. Who is this for? What's the purpose? What should it avoid? The more specific you are, the less generic the output. "This is for movement leaders who are skeptical of AI" is more useful than "Write for leaders." "Avoid hype; keep it calm and grounded" is more useful than "Make it good."

**Iteration:** You don't have to get it right the first time. Ask. Get a response. If it's off, say how: "That's too generic" or "The tone is wrong—more pastoral, less corporate" or "I need the second paragraph to emphasize X." Iteration is normal. It's how conversation works. You're not failing if you have to refine; you're communicating.

**Staying in the driver's seat:** You're the one who decides what to keep, what to change, what to reject. AI suggests; you choose. When you stay in the driver's seat, you're preserving voice and credibility. When you let AI drive, you're drifting toward replacement. So "prompting" well means: be clear, be specific, iterate, and stay in control. That's not engineering. That's communication.

## What This Means for You

You don't need to become a prompt engineer. You need to communicate clearly—and to treat the system as something you're in conversation with, not something you're optimizing. The same skills that make you a good teacher, a good collaborator, a good writer—clarity, specificity, the willingness to refine—those are the skills that make you good at working with AI. No technical expertise required. Just clarity, specificity, iteration, and the resolve to stay in the driver's seat.

---

**Reflection Questions:**

1. Where have you struggled to get useful responses from AI? What would clarity or specificity have changed?

2. How do you stay in the driver's seat when using AI—so that you're choosing, not just accepting?

3. What would it look like for you to treat AI as a conversation partner rather than a system to engineer?

